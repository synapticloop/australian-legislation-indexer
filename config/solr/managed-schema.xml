<?xml version="1.0" encoding="UTF-8" ?>
<schema name="nsw-legislation" version="1.7">
	<field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" />
	<field name="_version_" type="plong" indexed="false" stored="false"/>

	<!-- This is the name of the legislation / act etc. -->
	<field name="name" type="string" indexed="true" stored="true" />

	<!-- This is the jurisdiction of the legislation (NSW/ACT/Federal etc.) -->
	<field name="jurisdiction" type="string" indexed="true" stored="true" />

	<!-- Now for the actual content -->

	<!--
	  the level is the document level, will be like clause, part
	  -->
	<field name="level" type="string" indexed="true" stored="true" />
	<field name="heading" type="string" indexed="false" stored="true" />

	<field name="content" type="string" indexed="true" stored="true" />
	<field name="url_link" type="string" indexed="false" stored="true" />

	<field name="_text_" type="text_general" indexed="true" stored="false" multiValued="true"/>

	<dynamicField name="*_i"   type="pint"     indexed="true"  stored="true"/>
	<dynamicField name="*_is"  type="pints"    indexed="true"  stored="true"/>
	<dynamicField name="*_s"   type="string"   indexed="true"  stored="true" />
	<dynamicField name="*_ss"  type="strings"  indexed="true"  stored="true"/>
	<dynamicField name="*_l"   type="plong"    indexed="true"  stored="true"/>
	<dynamicField name="*_ls"  type="plongs"   indexed="true"  stored="true"/>
	<dynamicField name="*_b"   type="boolean"  indexed="true"  stored="true"/>
	<dynamicField name="*_bs"  type="booleans" indexed="true"  stored="true"/>
	<dynamicField name="*_f"   type="pfloat"   indexed="true"  stored="true"/>
	<dynamicField name="*_fs"  type="pfloats"  indexed="true"  stored="true"/>
	<dynamicField name="*_d"   type="pdouble"  indexed="true"  stored="true"/>
	<dynamicField name="*_ds"  type="pdoubles" indexed="true"  stored="true"/>
	<dynamicField name="*_dt"  type="pdate"    indexed="true"  stored="true"/>
	<dynamicField name="*_dts" type="pdates"   indexed="true"  stored="true"/>
	<dynamicField name="*_t"   type="text_general" indexed="true" stored="true" multiValued="false"/>
	<dynamicField name="*_txt" type="text_general" indexed="true" stored="true"/>

	<dynamicField name="random_*" type="random"/>
	<dynamicField name="ignored_*" type="ignored"/>

	<!-- Type used for data-driven schema, to add a string copy for each text field -->
	<dynamicField name="*_str" type="strings" stored="false" docValues="true" indexed="false" useDocValuesAsStored="false"/>

	<dynamicField name="*_p"  type="location" indexed="true" stored="true"/>
	<dynamicField name="*_srpt"  type="location_rpt" indexed="true" stored="true"/>

	<!-- payloaded dynamic fields -->
	<dynamicField name="*_dpf" type="delimited_payloads_float" indexed="true"  stored="true"/>
	<dynamicField name="*_dpi" type="delimited_payloads_int" indexed="true"  stored="true"/>
	<dynamicField name="*_dps" type="delimited_payloads_string" indexed="true"  stored="true"/>

	<dynamicField name="attr_*" type="text_general" indexed="true" stored="true" multiValued="true"/>

	<!-- Field to use to determine and enforce document uniqueness.
		Unless this field is marked with required="false", it will be a required field
	-->
	<uniqueKey>id</uniqueKey>

	<!-- copyField commands copy one field to another at the time a document
		 is added to the index.  It's used either to index the same field differently,
		 or to add multiple fields to the same field for easier/faster searching.

	<copyField source="sourceFieldName" dest="destinationFieldName"/>
	-->

	<!-- The StrField type is not analyzed, but indexed/stored verbatim. -->
	<fieldType name="string" class="solr.StrField" sortMissingLast="true" />
	<fieldType name="strings" class="solr.StrField" sortMissingLast="true" multiValued="true" />

	<!-- boolean type: "true" or "false" -->
	<fieldType name="boolean" class="solr.BoolField" sortMissingLast="true"/>
	<fieldType name="booleans" class="solr.BoolField" sortMissingLast="true" multiValued="true"/>

	<!--
		Numeric field types that index values using KD-trees.
		Point fields don't support FieldCache, so they must have docValues enabled if needed for sorting, faceting, functions, etc.
		This is the default, so it does not need to be set explicitly.
	-->
	<fieldType name="pint" class="solr.IntPointField"/>
	<fieldType name="pfloat" class="solr.FloatPointField"/>
	<fieldType name="plong" class="solr.LongPointField"/>
	<fieldType name="pdouble" class="solr.DoublePointField"/>

	<fieldType name="pints" class="solr.IntPointField" multiValued="true"/>
	<fieldType name="pfloats" class="solr.FloatPointField" multiValued="true"/>
	<fieldType name="plongs" class="solr.LongPointField" multiValued="true"/>
	<fieldType name="pdoubles" class="solr.DoublePointField" multiValued="true"/>
	<fieldType name="random" class="solr.RandomSortField" indexed="true"/>

	<!-- since fields of this type are by default not stored or indexed,
		 any data added to them will be ignored outright.  -->
	<fieldType name="ignored" stored="false" indexed="false" multiValued="true" docValues="false" class="solr.StrField" />

	<!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
			 is a more restricted form of the canonical representation of dateTime
			 http://www.w3.org/TR/xmlschema-2/#dateTime
			 The trailing "Z" designates UTC time and is mandatory.
			 Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
			 All other components are mandatory.

			 Expressions can also be used to denote calculations that should be
			 performed relative to "NOW" to determine the value, ie...

						 NOW/HOUR
								... Round to the start of the current hour
						 NOW-1DAY
								... Exactly 1 day prior to now
						 NOW/DAY+6MONTHS+3DAYS
								... 6 months and 3 days in the future from the start of
										the current day

		-->
	<!-- KD-tree versions of date fields -->
	<fieldType name="pdate" class="solr.DatePointField"/>
	<fieldType name="pdates" class="solr.DatePointField" multiValued="true"/>

	<!--Binary data type. The data should be sent/retrieved in as Base64 encoded Strings -->
	<fieldType name="binary" class="solr.BinaryField"/>

	<!--
	RankFields can be used to store scoring factors to improve document ranking. They should be used
	in combination with RankQParserPlugin.
	(experimental)
	-->
	<fieldType name="rank" class="solr.RankField"/>

	<!-- solr.TextField allows the specification of custom text analyzers
			 specified as a tokenizer and a list of token filters. Different
			 analyzers may be specified for indexing and querying.

			 The optional positionIncrementGap puts space between multiple fields of
			 this type on the same document, with the purpose of preventing false phrase
			 matching across fields.

			 For more info on customizing your analyzer chain, please see
			 https://solr.apache.org/guide/solr/latest/indexing-guide/document-analysis.html#using-analyzers-tokenizers-and-filters
	 -->

	<!-- One can also specify an existing Analyzer class that has a
			 default constructor via the class attribute on the analyzer element.
			 Example:
	<fieldType name="text_greek" class="solr.TextField">
		<analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
	</fieldType>
	-->

	<!-- A text field that only splits on whitespace for exact matching of words -->
	<dynamicField name="*_ws" type="text_ws"  indexed="true"  stored="true"/>
	<fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
		<analyzer>
			<tokenizer name="whitespace"/>
		</analyzer>
	</fieldType>

	<!-- A general text field that has reasonable, generic
			 cross-language defaults: it tokenizes with StandardTokenizer,
			 removes stop words from case-insensitive "stopwords.txt"
			 (empty by default), and down cases.  At query time only, it
			 also applies synonyms.
	-->
	<fieldType name="text_general" class="solr.TextField" positionIncrementGap="100" multiValued="true">
		<analyzer type="index">
			<tokenizer name="standard"/>
			<filter name="stop" ignoreCase="true" words="stopwords.txt" />
			<!-- in this example, we will only use synonyms at query time
			<filter name="synonymGraph" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
			<filter name="flattenGraph"/>
			-->
			<filter name="lowercase"/>
		</analyzer>
		<analyzer type="query">
			<tokenizer name="standard"/>
			<filter name="stop" ignoreCase="true" words="stopwords.txt" />
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
			<filter name="lowercase"/>
		</analyzer>
	</fieldType>


	<!-- SortableTextField generaly functions exactly like TextField,
			 except that it supports, and by default uses, docValues for sorting (or faceting)
			 on the first 1024 characters of the original field values (which is configurable).

			 This makes it a bit more useful then TextField in many situations, but the trade-off
			 is that it takes up more space on disk; which is why it's not used in place of TextField
			 for every fieldType in this _default schema.
	-->
	<dynamicField name="*_t_sort" type="text_gen_sort" indexed="true" stored="true" multiValued="false"/>
	<dynamicField name="*_txt_sort" type="text_gen_sort" indexed="true" stored="true"/>
	<fieldType name="text_gen_sort" class="solr.SortableTextField" positionIncrementGap="100" multiValued="true">
		<analyzer type="index">
			<tokenizer name="standard"/>
			<filter name="stop" ignoreCase="true" words="stopwords.txt" />
			<filter name="lowercase"/>
		</analyzer>
		<analyzer type="query">
			<tokenizer name="standard"/>
			<filter name="stop" ignoreCase="true" words="stopwords.txt" />
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
			<filter name="lowercase"/>
		</analyzer>
	</fieldType>

	<!-- A text field with defaults appropriate for English: it tokenizes with StandardTokenizer,
			 removes English stop words (lang/stopwords_en.txt), down cases, protects words from protwords.txt, and
			 finally applies Porter's stemming.  The query time analyzer also applies synonyms from synonyms.txt. -->
	<dynamicField name="*_txt_en" type="text_en"  indexed="true"  stored="true"/>
	<fieldType name="text_en" class="solr.TextField" positionIncrementGap="100">
		<analyzer type="index">
			<tokenizer name="standard"/>
			<!-- in this example, we will only use synonyms at query time
			<filter name="synonymGraph" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
			<filter name="flattenGraph"/>
			-->
			<!-- Case insensitive stop word removal.
			-->
			<filter name="stop"
							ignoreCase="true"
							words="lang/stopwords_en.txt"
			/>
			<filter name="lowercase"/>
			<filter name="englishPossessive"/>
			<filter name="keywordMarker" protected="protwords.txt"/>
			<!-- Optionally you may want to use this less aggressive stemmer instead of PorterStemFilterFactory:
			<filter name="englishMinimalStem"/>
			-->
			<filter name="porterStem"/>
		</analyzer>
		<analyzer type="query">
			<tokenizer name="standard"/>
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
			<filter name="stop"
							ignoreCase="true"
							words="lang/stopwords_en.txt"
			/>
			<filter name="lowercase"/>
			<filter name="englishPossessive"/>
			<filter name="keywordMarker" protected="protwords.txt"/>
			<!-- Optionally you may want to use this less aggressive stemmer instead of PorterStemFilterFactory:
			<filter name="englishMinimalStem"/>
			-->
			<filter name="porterStem"/>
		</analyzer>
	</fieldType>

	<!-- A text field with defaults appropriate for English, plus
			 aggressive word-splitting and autophrase features enabled.
			 This field is just like text_en, except it adds
			 WordDelimiterGraphFilter to enable splitting and matching of
			 words on case-change, alpha numeric boundaries, and
			 non-alphanumeric chars.  This means certain compound word
			 cases will work, for example query "wi fi" will match
			 document "WiFi" or "wi-fi".
	-->
	<dynamicField name="*_txt_en_split" type="text_en_splitting"  indexed="true"  stored="true"/>
	<fieldType name="text_en_splitting" class="solr.TextField" positionIncrementGap="100" autoGeneratePhraseQueries="true">
		<analyzer type="index">
			<tokenizer name="whitespace"/>
			<!-- in this example, we will only use synonyms at query time
			<filter name="synonymGraph" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
			-->
			<!-- Case insensitive stop word removal.
			-->
			<filter name="stop"
							ignoreCase="true"
							words="lang/stopwords_en.txt"
			/>
			<filter name="wordDelimiterGraph" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
			<filter name="lowercase"/>
			<filter name="keywordMarker" protected="protwords.txt"/>
			<filter name="porterStem"/>
			<filter name="flattenGraph" />
		</analyzer>
		<analyzer type="query">
			<tokenizer name="whitespace"/>
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
			<filter name="stop"
							ignoreCase="true"
							words="lang/stopwords_en.txt"
			/>
			<filter name="wordDelimiterGraph" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
			<filter name="lowercase"/>
			<filter name="keywordMarker" protected="protwords.txt"/>
			<filter name="porterStem"/>
		</analyzer>
	</fieldType>

	<!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
			 but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
	<dynamicField name="*_txt_en_split_tight" type="text_en_splitting_tight"  indexed="true"  stored="true"/>
	<fieldType name="text_en_splitting_tight" class="solr.TextField" positionIncrementGap="100" autoGeneratePhraseQueries="true">
		<analyzer type="index">
			<tokenizer name="whitespace"/>
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>
			<filter name="stop" ignoreCase="true" words="lang/stopwords_en.txt"/>
			<filter name="wordDelimiterGraph" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
			<filter name="lowercase"/>
			<filter name="keywordMarker" protected="protwords.txt"/>
			<filter name="englishMinimalStem"/>
			<!-- this filter can remove any duplicate tokens that appear at the same position - sometimes
					 possible with WordDelimiterGraphFilter in conjuncton with stemming. -->
			<filter name="removeDuplicates"/>
			<filter name="flattenGraph" />
		</analyzer>
		<analyzer type="query">
			<tokenizer name="whitespace"/>
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>
			<filter name="stop" ignoreCase="true" words="lang/stopwords_en.txt"/>
			<filter name="wordDelimiterGraph" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
			<filter name="lowercase"/>
			<filter name="keywordMarker" protected="protwords.txt"/>
			<filter name="englishMinimalStem"/>
			<!-- this filter can remove any duplicate tokens that appear at the same position - sometimes
					 possible with WordDelimiterGraphFilter in conjuncton with stemming. -->
			<filter name="removeDuplicates"/>
		</analyzer>
	</fieldType>

	<!-- Just like text_general except it reverses the characters of
			 each token, to enable more efficient leading wildcard queries.
	-->
	<dynamicField name="*_txt_rev" type="text_general_rev"  indexed="true"  stored="true"/>
	<fieldType name="text_general_rev" class="solr.TextField" positionIncrementGap="100">
		<analyzer type="index">
			<tokenizer name="standard"/>
			<filter name="stop" ignoreCase="true" words="stopwords.txt" />
			<filter name="lowercase"/>
			<filter name="reversedWildcard" withOriginal="true"
							maxPosAsterisk="3" maxPosQuestion="2" maxFractionAsterisk="0.33"/>
		</analyzer>
		<analyzer type="query">
			<tokenizer name="standard"/>
			<filter name="synonymGraph" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
			<filter name="stop" ignoreCase="true" words="stopwords.txt" />
			<filter name="lowercase"/>
		</analyzer>
	</fieldType>

	<dynamicField name="*_phon_en" type="phonetic_en"  indexed="true"  stored="true"/>
	<fieldType name="phonetic_en" stored="false" indexed="true" class="solr.TextField" >
		<analyzer>
			<tokenizer name="standard"/>
			<filter name="doubleMetaphone" inject="false"/>
		</analyzer>
	</fieldType>

	<!-- lowercases the entire field value, keeping it as a single token.  -->
	<dynamicField name="*_s_lower" type="lowercase"  indexed="true"  stored="true"/>
	<fieldType name="lowercase" class="solr.TextField" positionIncrementGap="100">
		<analyzer>
			<tokenizer name="keyword"/>
			<filter name="lowercase" />
		</analyzer>
	</fieldType>

	<!--
		Example of using PathHierarchyTokenizerFactory at index time, so
		queries for paths match documents at that path, or in descendent paths
	-->
	<dynamicField name="*_descendent_path" type="descendent_path"  indexed="true"  stored="true"/>
	<fieldType name="descendent_path" class="solr.TextField">
		<analyzer type="index">
			<tokenizer name="pathHierarchy" delimiter="/" />
		</analyzer>
		<analyzer type="query">
			<tokenizer name="keyword" />
		</analyzer>
	</fieldType>

	<!--
		Example of using PathHierarchyTokenizerFactory at query time, so
		queries for paths match documents at that path, or in ancestor paths
	-->
	<dynamicField name="*_ancestor_path" type="ancestor_path"  indexed="true"  stored="true"/>
	<fieldType name="ancestor_path" class="solr.TextField">
		<analyzer type="index">
			<tokenizer name="keyword" />
		</analyzer>
		<analyzer type="query">
			<tokenizer name="pathHierarchy" delimiter="/" />
		</analyzer>
	</fieldType>

	<!-- This point type indexes the coordinates as separate fields (subFields)
		If subFieldType is defined, it references a type, and a dynamic field
		definition is created matching *___<typename>.  Alternately, if
		subFieldSuffix is defined, that is used to create the subFields.
		Example: if subFieldType="double", then the coordinates would be
			indexed in fields myloc_0___double,myloc_1___double.
		Example: if subFieldSuffix="_d" then the coordinates would be indexed
			in fields myloc_0_d,myloc_1_d
		The subFields are an implementation detail of the fieldType, and end
		users normally should not need to know about them.
	 -->
	<dynamicField name="*_point" type="point"  indexed="true"  stored="true"/>
	<fieldType name="point" class="solr.PointType" dimension="2" subFieldSuffix="_d"/>

	<!-- A specialized field for geospatial search filters and distance sorting. -->
	<fieldType name="location" class="solr.LatLonPointSpatialField"/>

	<!-- A geospatial field type that supports multiValued and polygon shapes.
		For more information about this and other spatial fields see:
		https://solr.apache.org/guide/solr/latest/query-guide/spatial-search.html
	-->
	<fieldType name="location_rpt" class="solr.SpatialRecursivePrefixTreeFieldType"
						 geo="true" distErrPct="0.025" maxDistErr="0.001" distanceUnits="kilometers" />

	<!-- Payloaded field types -->
	<fieldType name="delimited_payloads_float" stored="false" indexed="true" class="solr.TextField">
		<analyzer>
			<tokenizer name="whitespace"/>
			<filter name="delimitedPayload" encoder="float"/>
		</analyzer>
	</fieldType>
	<fieldType name="delimited_payloads_int" stored="false" indexed="true" class="solr.TextField">
		<analyzer>
			<tokenizer name="whitespace"/>
			<filter name="delimitedPayload" encoder="integer"/>
		</analyzer>
	</fieldType>
	<fieldType name="delimited_payloads_string" stored="false" indexed="true" class="solr.TextField">
		<analyzer>
			<tokenizer name="whitespace"/>
			<filter name="delimitedPayload" encoder="identity"/>
		</analyzer>
	</fieldType>
</schema>
